<?xml version="1.0" encoding="UTF-8"?>
<p>Problems with the sensitivity and specificity of systematic IS literature searches were already being reported in 2010 (
 <xref rid="B10" ref-type="bibr">10</xref>, 
 <xref rid="B11" ref-type="bibr">11</xref>). In response, Lokker et al. and McKibbon et al. developed search filters to identify different types of IS articles (general, theoretical, IS instruments, application-focused) from CINAHL and MEDLINE (
 <xref rid="B10" ref-type="bibr">10</xref>, 
 <xref rid="B11" ref-type="bibr">11</xref>). For MEDLINE, these filters' sensitivity ranged from 85 to 90%, with specificity ranging from 65 to 75% depending on the type of article (
 <xref rid="B11" ref-type="bibr">11</xref>). For CINAHL, their retrieval efficacy was comparable, i.e., they resulted in a large number of results, many of which were irrelevant (
 <xref rid="B10" ref-type="bibr">10</xref>). In contrast, search strings for clear, well-defined concepts, such as 
 <italic>randomized clinical trials</italic> (RCTs), showed both sensitivity and specificity over 99%. Concepts with a high variability of search terms such as patient and public involvement reach comparable retrieval rates as IS search strings (
 <xref rid="B12" ref-type="bibr">12</xref>â€“
 <xref rid="B14" ref-type="bibr">14</xref>).
</p>
