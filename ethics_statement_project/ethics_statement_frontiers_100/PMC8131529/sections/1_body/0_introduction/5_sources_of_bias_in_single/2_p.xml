<?xml version="1.0" encoding="UTF-8"?>
<p>Unlike for group design research, there is no widely agreed upon tool for assessing bias in SCD studies. However, 
 <xref rid="B20" ref-type="bibr">Reichow et al. (2018)</xref> propose that risks of bias in SCDs are analogous to risks of bias in group-design studies. They describe three risk of bias categories, including: (a) selection bias (systematic differences in baseline characteristics of participants), (b) performance bias (systematic differences between participants in care or exposure to factors other than the intervention), (c) and detection bias (systematic differences between participants in the measurement and reporting of outcomes). Each of these sources of bias can increase the likelihood that an intervention procedure will be determined to bear a functional relation with the outcome, when it in fact does not. For example, a researcher could assign participants to a control condition if they have some reason to suspect the intervention will not be successful for that student during a particular session (selection bias). Or, researchers may know which participants are assigned to an intervention condition, and treat them more favorably than participants in the control condition in ways unrelated to the intervention being examined (performance bias). Finally, researchers who track data on participant outcomes may be aware of when the child is in a treatment condition, and may score that child more favorably than when the child is in the control condition (detection bias). In addition to these sources of bias, researchers can also interpret evidence more favorably than is warranted, and determine that a set of intervention practices are effective for improving outcomes, when the data in fact do not support this assertion (
 <xref rid="B3" ref-type="bibr">Bottema-Beutel and Crowley, 2020</xref>).
</p>
